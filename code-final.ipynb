{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00b8d8fd-b7d7-4d17-b48c-f1fe26c1fdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45185d43-142f-4de5-8cd1-c1bead359fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jahag\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jahag\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download necessary NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76a89efb-b9bf-4097-9b4d-6c8158ebd794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train_file_path = \"Racial_train.csv\"  # Update with correct file name\n",
    "val_file_path = \"Racial_val.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a3fe92e-bca6-40da-a6a0-8fef772555ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the dataset exists and columns are correct\n",
    "df_train = pd.read_csv(train_file_path)\n",
    "df_val = pd.read_csv(val_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b11a253-d6d0-4a4d-b98a-007641f97fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_text    0\n",
      "labels        0\n",
      "dtype: int64\n",
      "clean_text    0\n",
      "labels        0\n",
      "dtype: int64\n",
      "Index(['clean_text', 'labels'], dtype='object')\n",
      "Index(['clean_text', 'labels'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values and columns\n",
    "print(df_train.isnull().sum())\n",
    "print(df_val.isnull().sum())\n",
    "\n",
    "print(df_train.columns)\n",
    "print(df_val.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a822cc2-ae9c-490d-bfd3-d2617586de12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = text.lower()\n",
    "    text = re.sub(f\"[{string.punctuation}]\", \"\", text)\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "    words = text.split()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stopwords.words(\"english\")]\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ae69521-2ebe-4121-aad5-d30a6ef87c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing\n",
    "df_train[\"clean_text\"] = df_train[\"clean_text\"].apply(preprocess_text)\n",
    "df_val[\"clean_text\"] = df_val[\"clean_text\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65dd9261-cd21-4e8c-b630-0e8eb2d86b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,3), max_features=5000)\n",
    "X_train = vectorizer.fit_transform(df_train[\"clean_text\"])\n",
    "X_val = vectorizer.transform(df_val[\"clean_text\"])\n",
    "y_train = df_train[\"labels\"]\n",
    "y_val = df_val[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cd6a4523-01d9-4b5c-b3d6-a90e2cdcbf29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(vectorizer, \"tfidf_vectorizer.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27ae525f-4c16-402a-b7b2-e80d2894ba14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jahag\\anaconda3\\lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Handle Class Imbalance with SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf740fc6-71ba-4489-85c3-97bd6405cf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure directory for saving models exists\n",
    "if not os.path.exists(\"models\"):\n",
    "    os.makedirs(\"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "88999dc0-b014-4eaa-b8c4-517334907536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models and parameters for grid search\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(class_weight=\"balanced\"),\n",
    "    \"SVM\": SVC(class_weight=\"balanced\"),\n",
    "    \"Random Forest\": RandomForestClassifier(class_weight=\"balanced\"),\n",
    "    \"MLP\": MLPClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f92badd8-f909-43a3-a123-d339eb5178e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"Logistic Regression\": {\"C\": [0.1, 1, 10]},\n",
    "    \"SVM\": {\"C\": [0.1, 1, 10], \"kernel\": [\"linear\", \"rbf\"]},\n",
    "    \"Random Forest\": {\"n_estimators\": [100, 200], \"max_depth\": [10, 20]},\n",
    "    \"MLP\": {\"hidden_layer_sizes\": [(50,), (100,)], \"alpha\": [0.0001, 0.001]}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad087e84-2c48-4aa3-a28c-eabd925c0d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation and model training\n",
    "best_model = None\n",
    "best_f1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4b2c7351-9899-4b30-9183-95ca08d3670c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression...\n",
      "Logistic Regression - F1 Score: 0.6592, Accuracy: 0.7581\n",
      "Classification Report for Logistic Regression:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.84       774\n",
      "           1       0.50      0.45      0.48       247\n",
      "\n",
      "    accuracy                           0.76      1021\n",
      "   macro avg       0.67      0.65      0.66      1021\n",
      "weighted avg       0.75      0.76      0.75      1021\n",
      "\n",
      "Training SVM...\n",
      "SVM - F1 Score: 0.6335, Accuracy: 0.7395\n",
      "Classification Report for SVM:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83       774\n",
      "           1       0.46      0.42      0.44       247\n",
      "\n",
      "    accuracy                           0.74      1021\n",
      "   macro avg       0.64      0.63      0.63      1021\n",
      "weighted avg       0.73      0.74      0.74      1021\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest - F1 Score: 0.5840, Accuracy: 0.7669\n",
      "Classification Report for Random Forest:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.94      0.86       774\n",
      "           1       0.55      0.21      0.31       247\n",
      "\n",
      "    accuracy                           0.77      1021\n",
      "   macro avg       0.67      0.58      0.58      1021\n",
      "weighted avg       0.73      0.77      0.73      1021\n",
      "\n",
      "Training MLP...\n",
      "MLP - F1 Score: 0.6368, Accuracy: 0.7512\n",
      "Classification Report for MLP:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.87      0.84       774\n",
      "           1       0.48      0.39      0.43       247\n",
      "\n",
      "    accuracy                           0.75      1021\n",
      "   macro avg       0.65      0.63      0.64      1021\n",
      "weighted avg       0.74      0.75      0.74      1021\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    grid = GridSearchCV(model, param_grid[name], scoring=\"f1_macro\", cv=StratifiedKFold(n_splits=5), n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_estimator = grid.best_estimator_\n",
    "    \n",
    "    # Save best model using joblib\n",
    "    joblib.dump(best_estimator, f\"models/{name.replace(' ', '_').lower()}_model.pkl\")\n",
    "    \n",
    "    # Predict on validation data\n",
    "    y_pred = best_estimator.predict(X_val)\n",
    "    \n",
    "    # Evaluate model\n",
    "    f1 = f1_score(y_val, y_pred, average=\"macro\")\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    \n",
    "    print(f\"{name} - F1 Score: {f1:.4f}, Accuracy: {acc:.4f}\")\n",
    "    \n",
    "    # Print Classification Report\n",
    "    print(f\"Classification Report for {name}:\\n\", classification_report(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48fbde4d-5584-4ba2-a66e-47c4d3b0fbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "###test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9d0381a3-f18f-4581-b5d6-f083193e09af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6a3802b4-31cd-4b73-a6b4-70e48f813ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data (without labels)\n",
    "test_file_path = \"Racial_test_without_labels.csv\"\n",
    "df_test = pd.read_csv(test_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fbe11fbd-328d-494f-940a-9ec1f27925d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved TF-IDF vectorizer\n",
    "vectorizer = joblib.load(\"tfidf_vectorizer.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "db6da63f-6d33-4b07-9bf4-8a0dca6dc9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)  # Remove punctuation\n",
    "    text = re.sub(r\"\\d+\", \"\", text)  # Remove numbers\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7b454f1d-aa25-4688-a610-86aabd62aa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing\n",
    "df_test[\"clean_text\"] = df_test[\"clean_text\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "668b8924-d40c-4092-aace-96497aaa47e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert test text to numerical features\n",
    "X_test = vectorizer.transform(df_test[\"clean_text\"]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7318ad78-cb86-4803-a9d8-5b1cda51a550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of trained models\n",
    "model_names = [\n",
    "    \"Logistic_Regression_model\",\n",
    "    \"svm_model\",\n",
    "    \"random_forest_model\",\n",
    "    \"mlp_model\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "378acaf4-47f0-454b-9b6c-bf8ac4f6103d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved for Logistic_Regression_model in Logistic_Regression_model_predictions.csv\n",
      "Predictions saved for svm_model in svm_model_predictions.csv\n",
      "Predictions saved for random_forest_model in random_forest_model_predictions.csv\n",
      "Predictions saved for mlp_model in mlp_model_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "for model_name in model_names:\n",
    "    # Load the model\n",
    "    model = joblib.load(f\"{model_name}.pkl\")\n",
    "    \n",
    "    # Predict class labels\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Save predictions in a separate CSV file\n",
    "    output_file = f\"{model_name}_predictions.csv\"\n",
    "    df_output = pd.DataFrame({\"clean_text\": df_test[\"clean_text\"], \"Predicted_Label\": y_pred})\n",
    "    df_output.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"Predictions saved for {model_name} in {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402dd4da-63fb-49b1-8f78-41145981d3ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
